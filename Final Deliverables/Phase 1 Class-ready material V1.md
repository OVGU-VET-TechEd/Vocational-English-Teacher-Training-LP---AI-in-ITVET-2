<!--
author:   Ozan Eylul Yukunc 
email:    your.email@example.com
version:  1.0.0
language: en
narrator: US English Female

@style
<style>
.lia-slide__container {
  font-size: 1.1em;
}
</style>
@end

-->

# Pre-Planning & Tool Selection (60 Minutes)

<br>

 Learning Overview

**Goal:** To know exactly why we cannot put student names into free AI tools and how to spot vocational errors.

<br>

**Learning Outcomes**

<br>

Teachers will be able to:

* Select **nonâ€“high-risk AI tools** appropriate for Vocational English
* Identify **GDPR-safe classroom practices**
* Conduct a **basic AI risk and bias check** before classroom use

<br>

**Tools we will use:**

* **DeepL** (Free Web Version)
* **ChatGPT** (Free Version, Guest Mode)

---

## Activity 1: The "Terms of Service" Hunt

**Time:** 20 Minutes

**Format:** Small Groups (3-4 teachers)

**Concept:** We will analyze the assumption "Education Use = Private." Is it true or not?

Instructions

Open **DeepL.com** and **OpenAI.com** on your devices and locate "Terms of Use" or "Privacy Policy" links at the bottom of those websites and fill this checklist:

![Checklist Image](checklist_image.jpg "Checklist for AI Tools")

---

### Second Phase: "Who found the clause about training AI on your data?"


**Answers:**

**DeepL (Free): NO, it is not safe.** The free version explicitly states they store texts and use them to train their algorithms. Lesson: Only DeepL Pro offers data privacy.

**ChatGPT (Free): NO, not by default.** OpenAI uses inputs to train models unless you go into Settings and turn off "Model Improvement" or use the specific "Team/Enterprise" workspace.


---

### Reflection Question

As teachers, what can we infer from this experience?

<br>

We must be aware of the terms and services before selecting an AI tool to determine any privacy, violation and/or ethical issues.

---

## Activity 2: The "Hallucination & Bias" Simulation

**Time:** 30 Minutes

**Format:** Live Simulation

**Concept:** Teachers will force the AI to fail to understand the necessity of human oversight in Vocational English.

---

### Part A: The "Gender Mirror" (Bias Check)

**Instructions:**

1. Open **Google Translate** or **DeepL**.
2. Set the language pair: **English** to **Native language** and paste this specifically engineered text that uses gender-neutral pronouns:

> "The doctor yelled at the nurse because she was late. The nurse was annoyed because he had been working all night."

---

### The Results: Let's Look at the Translation

<br>

* Did the AI translate "doctor" as Male or Female?
* Did it translate "nurse" as Male or Female?

<br>

**Reflection:** Discuss how this impacts vocational identity. If a male student is training to be a nurse, will the AI constantly misgender him in professional scenarios?

---

### Part B: The "Polysemy Trap" (Technical Accuracy)

**Vocational Context:** Mechanical Engineering & Logistics

**Concept:** Polysemous words (words with multiple meanings) are the most dangerous part of Vocational English.


<br>

Instructions

1. Open **ChatGPT**.
2. Paste the following prompt:

> "Translate these safety instructions for a construction site into [Target Language]: 'Ensure the crane is secured before the draft picks up. Do not strip the nut when tightening the bolt.'"

---

### The Test: Check the Technical Accuracy

* **"Crane":** Did it translate as the bird or the machine?
* **"Draft":** Did it translate as a bank check, a sketch, or wind/airflow? (It should be wind/airflow).
* **"Strip the nut":** Did it translate as "removing a fruit shell" or "damaging the threads of a metal fastener"?

---

## Final Reflection

Discuss what you have learned about AI Usage

<br>

Assessment for Phase 1

Write a reflection paper including these four topics:

1. What kind of bias can AI have?
2. What changes will you add in your prompts to prevent it?
3. How can you prevent the translation errors of AI that happens due to Polysemy?
4. What to consider when choosing an AI tool?
